{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":17839.767022,"end_time":"2023-08-06T05:17:17.309827","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-06T00:19:57.542805","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generacion de texto con GPT2 de KerasNLP\n\n**Author:** David Alonso Quispe Castillo<br>\n**Date created:** 14/07/2023<br>\n**Last modified:** 17/08/2023<br>\n**Objetivo:** Usar el modelo GPT-2 de KerasNLP y los generadores de texto (samplers) para la generación de texto.","metadata":{"id":"inev2z-Zzb7w","papermill":{"duration":0.010894,"end_time":"2023-08-06T00:20:08.095813","exception":false,"start_time":"2023-08-06T00:20:08.084919","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"En este proyecto, basado en el trabajo previo de [Chen Qian](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/gpt2_text_generation_with_kerasnlp.ipynb#scrollTo=76gl9HSIF-uB), utilizaremos [KerasNLP](https://keras.io/keras_nlp/) para cargar un modelo de lenguaje grande  (LLM) pre-entrenado - el modelo [GPT-2 ](https://openai.com/research/better-language-models), desarrollado por OpenAI. Aprovecharemos las capacidades de generación de texto de este modelo para crear texto basado en una entrada proporcionada por el usuario. Además, se demostrará cómo GPT-2 puede adaptarse rápidamente a otros idiomas, como el español.","metadata":{"id":"lniu_DmLzb70","papermill":{"duration":0.009823,"end_time":"2023-08-06T00:20:08.115892","exception":false,"start_time":"2023-08-06T00:20:08.106069","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:40:52.025573Z","iopub.execute_input":"2023-08-06T21:40:52.026062Z","iopub.status.idle":"2023-08-06T21:40:53.446676Z","shell.execute_reply.started":"2023-08-06T21:40:52.026022Z","shell.execute_reply":"2023-08-06T21:40:53.444419Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:731\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    729\u001b[0m         os\u001b[38;5;241m.\u001b[39mrmdir(path)\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 731\u001b[0m         \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m         \u001b[38;5;66;03m# symlinks to directories are forbidden, see bug #1669\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:729\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    727\u001b[0m     os\u001b[38;5;241m.\u001b[39mclose(fd)\n\u001b[1;32m    728\u001b[0m     fd_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     onerror(os\u001b[38;5;241m.\u001b[39mrmdir, path, sys\u001b[38;5;241m.\u001b[39mexc_info())\n","\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: '/kaggle/working/'"],"ename":"OSError","evalue":"[Errno 16] Device or resource busy: '/kaggle/working/'","output_type":"error"}]},{"cell_type":"markdown","source":"https://www.tensorflow.org/install/source?hl=es-419#gpu","metadata":{"id":"CWbCbP9BwYmY","papermill":{"duration":0.009691,"end_time":"2023-08-06T00:20:08.136013","exception":false,"start_time":"2023-08-06T00:20:08.126322","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"##  Antes de comenzar (Colab)\n\nColab ofrece diferentes tipos de entornos de ejecución. Asegúrate de ir a **Entorno de ejecución -> Cambiar tipo de entorno de ejecución** y seleccionar el entorno de ejecución con aceleración de hardware GPU (que debería tener >12 GB de RAM del host y ~15 GB de RAM de la GPU) ya que ajustaremos finamente el modelo GPT-2. Ejecutar este tutorial en un entorno de ejecución de CPU tomaría horas.\n\nen colab las versiones usadas son:\n\n\n\nVersión de keras-nlp: 0.6.0\n\nVersión de TensorFlow: 2.13.0\n\nVersión de Python: 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n\nVersión de Cudnn:\ndefine CUDNN_MAJOR 8\ndefine CUDNN_MINOR 9\ndefine CUDNN_PATCHLEVEL 0\ndefine CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n\n/* cannot use constexpr here since this is a C-only file */\n\nVersión de CUDA :\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\n\nDispositivo GPU : /physical_device:GPU:0\n\nEscpecificaciones de gpu:\nWed Jul 19 21:24:51 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","metadata":{"id":"VWjhy_btzb71","papermill":{"duration":0.00951,"end_time":"2023-08-06T00:20:08.155214","exception":false,"start_time":"2023-08-06T00:20:08.145704","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"##  Antes de comenzar (en Amazon Sagemaker Studio lab)\n\nSe optó por usar estas versiones para la ejecución:\n- Python: 3.9.15\n- Tensorflow: 2.11.0\n- keras-nlp: 0.6.0\n\nLa razon de usar dichas versiones es porque sage maker studio lab, viene por defecto con:\n- CUDA: 11.2\n- cudnn: 8.1\n\n\nSi solamente instalas tensorflow en tu conda enviroment, y quieres ejecutar la funcion generate() del modelo te aparecerá un error de dependecia por parte del paquete tensorflow-text, y si intentas realizar la instalacion de la version correcta mediante el siguiente codigo: pip install tensorflow-text~=2.11.0, no se instalará esa version, sino la mas reciente que es la 2.13.0 y ademas que instalará toda la version completa de tensorflow 2.13.0, para instalar la version necesaria que es la 2.11.0 debes ejecutar lo siguiente:\n\npip install tensorflow==2.11.0\npip install h5py\npip install typing-extensions\npip install wheel\n\ny al final:\n\npip install tensorflow-text~=2.11.0\n\ninstalar desde ya ipywidgets sino en algun momento saldra error, no recuerdo cuando dx\npip install ipywidgets\n\ninstalar esta version de protobuf porque habia error al momento de entrenar el modelo:\npip install protobuf~=3.20.0\n\n(hasta el momento esta entrenando en el primer epoch, pero esta mostrando estos alertas de error:)\n\n\nERROR:absl:module 'tensorflow_datasets.core' has no attribute 'utils'\nTraceback (most recent call last):\n  File \"/home/studio-lab-user/.conda/envs/gpt/lib/python3.9/site-packages/tensorflow_datasets/__init__.py\", line 59, in <module>\n    from tensorflow_datasets import audio\n  File \"/home/studio-lab-user/.conda/envs/gpt/lib/python3.9/site-packages/tensorflow_datasets/audio/__init__.py\", line 19, in <module>\n    from tensorflow_datasets.audio.commonvoice import CommonVoice\n  File \"/home/studio-lab-user/.conda/envs/gpt/lib/python3.9/site-packages/tensorflow_datasets/audio/commonvoice.py\", line 27, in <module>\n    import tensorflow_datasets.public_api as tfds\n  File \"/home/studio-lab-user/.conda/envs/gpt/lib/python3.9/site-packages/tensorflow_datasets/public_api.py\", line 57, in <module>\n    deprecated = core.utils.docs.deprecated(deprecated)\nAttributeError: module 'tensorflow_datasets.core' has no attribute 'utils'\nEpoch 1/10\n2023-07-19 22:04:00.467755: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. gpt2_causal_lm/gpt2_backbone/embeddings_dropout/dropout/random_uniform/RandomUniform\n2023-07-19 22:04:01.556077: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n 682/2425 [=======>......................] - ETA: 13:11 - loss: 3.4543 - sparse_categorical_accuracy: 0.3821","metadata":{"id":"HVTm8HvfnoEj","jp-MarkdownHeadingCollapsed":true,"papermill":{"duration":0.009579,"end_time":"2023-08-06T00:20:08.174678","exception":false,"start_time":"2023-08-06T00:20:08.165099","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Introducción a los Modelos de Lenguaje Generativos de Gran Escala (LLMs)\n\nLos Modelos de Lenguaje Grande (LLMs, por sus siglas en inglés) son un tipo de modelos de aprendizaje automático que se entrenan en un gran corpus de datos de texto para generar resultados en varias tareas de Procesamiento del Lenguaje Natural (NLP, por sus siglas en inglés), como generación de texto, respuesta a preguntas o traducción automática.\n\nLos LLMs generativos se basan típicamente en redes neuronales de aprendizaje profundo, como la arquitectura [Transformer](https://arxiv.org/abs/1706.03762) inventada por investigadores de Google en 2017, y se entrenan con grandes cantidades de datos de texto, a menudo involucrando miles de millones de palabras. Estos modelos, como [LaMDA](https://blog.google/technology/ai/lamda/) y [PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html) de Google, se entrenan con conjuntos de datos extensos provenientes de diversas fuentes de datos, lo que les permite generar resultados para múltiples tareas. El núcleo de los LLMs generativos consiste en predecir la siguiente palabra en una oración, a menudo conocido como **Preentrenamiento LM Causal**. De esta manera, los LLMs pueden generar texto coherente basado en las indicaciones del usuario. Para obtener una discusión más pedagógica sobre los modelos de lenguaje, puedes consultar la [clase de Stanford CS324 LLM](https://stanford-cs324.github.io/winter2022/lectures/introduction/).","metadata":{"id":"Jz1PYPIczb74","papermill":{"duration":0.009937,"end_time":"2023-08-06T00:20:08.194274","exception":false,"start_time":"2023-08-06T00:20:08.184337","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Instalamos KerasNLP e Importamos Dependencias","metadata":{"papermill":{"duration":0.009937,"end_time":"2023-08-06T00:20:08.214248","exception":false,"start_time":"2023-08-06T00:20:08.204311","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install -q keras-nlp","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:20:08.236094Z","iopub.status.busy":"2023-08-06T00:20:08.235338Z","iopub.status.idle":"2023-08-06T00:20:23.150430Z","shell.execute_reply":"2023-08-06T00:20:23.149158Z"},"id":"mnDHnN1Yzb72","outputId":"498b8689-12f3-452b-ef66-83150f9363d8","papermill":{"duration":14.929057,"end_time":"2023-08-06T00:20:23.153156","exception":false,"start_time":"2023-08-06T00:20:08.224099","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import keras_nlp\nimport tensorflow as tf\nfrom tensorflow import keras\nimport time\nimport sys\n\nprint(\"Versión de keras-nlp:\", keras_nlp.__version__)\nprint(\"\\nVersión de TensorFlow:\", tf.__version__)\nprint(\"\\nVersión de Python:\", sys.version)\n\nprint(\"\\nVersión de Cudnn:\")\n!cat /usr/include/x86_64-linux-gnu/cudnn_v*.h | grep CUDNN_MAJOR -A 2\n!cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2\n\n\nprint(\"\\nVersión de CUDA :\")\n!nvcc --version\nprint(\"\\nDispositivo GPU :\", tf.config.list_physical_devices('GPU')[0].name)\nprint(\"\\nEscpecificaciones de gpu:\")\n!nvidia-smi","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:20:23.175482Z","iopub.status.busy":"2023-08-06T00:20:23.175163Z","iopub.status.idle":"2023-08-06T00:20:37.610761Z","shell.execute_reply":"2023-08-06T00:20:37.609393Z"},"id":"yWKcA4SHzb73","outputId":"d94a4d66-b9c9-4570-fc6b-7870cffd5a8c","papermill":{"duration":14.449637,"end_time":"2023-08-06T00:20:37.613281","exception":false,"start_time":"2023-08-06T00:20:23.163644","status":"completed"},"tags":[]},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"Using TensorFlow backend\n"},{"name":"stderr","output_type":"stream","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"},{"name":"stdout","output_type":"stream","text":"Versión de keras-nlp: 0.6.1\n\n\n\nVersión de TensorFlow: 2.12.0\n\n\n\nVersión de Python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n\n\n\nVersión de Cudnn:\n\n#define CUDNN_MAJOR 8\n\n#define CUDNN_MINOR 9\n\n#define CUDNN_PATCHLEVEL 0\n\n--\n\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n\n\n\n/* cannot use constexpr here since this is a C-only file */\n\n\n\nVersión de CUDA :\n\nnvcc: NVIDIA (R) Cuda compiler driver\n\nCopyright (c) 2005-2022 NVIDIA Corporation\n\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\n\nCuda compilation tools, release 11.8, V11.8.89\n\nBuild cuda_11.8.r11.8/compiler.31833905_0\n\n\n\nDispositivo GPU : /physical_device:GPU:0\n\n\n\nEscpecificaciones de gpu:\n\nSun Aug  6 00:20:37 2023       \n\n+-----------------------------------------------------------------------------+\n\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n\n|-------------------------------+----------------------+----------------------+\n\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n\n|                               |                      |               MIG M. |\n\n|===============================+======================+======================|\n\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n\n| N/A   40C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n\n|                               |                      |                  N/A |\n\n+-------------------------------+----------------------+----------------------+\n\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n\n| N/A   43C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n\n|                               |                      |                  N/A |\n\n+-------------------------------+----------------------+----------------------+\n\n                                                                               \n\n+-----------------------------------------------------------------------------+\n\n| Processes:                                                                  |\n\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n\n|        ID   ID                                                   Usage      |\n\n|=============================================================================|\n\n|  No running processes found                                                 |\n\n+-----------------------------------------------------------------------------+\n"}]},{"cell_type":"markdown","source":"## Introducción a KerasNLP\n\nLa construcción y entrenamiento de Modelos de Lenguaje Grande (LLMs) desde cero son complejos y costosos. Afortunadamente, existen LLMs pre-entrenados disponibles para su uso inmediato. [KerasNLP](https://keras.io/keras_nlp/) proporciona una amplia variedad de puntos de control pre-entrenados que te permiten experimentar con modelos de última generación sin necesidad de entrenarlos desde cero.\n\nKerasNLP es una biblioteca de procesamiento del lenguaje natural que brinda soporte a los usuarios a lo largo de todo su ciclo de desarrollo. KerasNLP ofrece tanto modelos pre-entrenados como componentes modulares, lo que permite a los desarrolladores reutilizar fácilmente los modelos pre-entrenados o construir sus propios LLM.\n\nEn pocas palabras, para los LLMs generativos, KerasNLP ofrece:\n\n- Modelos pre-entrenados con el método `generate()`, por ejemplo en, `keras_nlp.models.GPT2CausalLM` y `keras_nlp.models.OPTCausalLM`.\n- Clase de muestreo (Sampler) que implementa algoritmos de generación como Top-K, Beam y búsqueda contrastiva. Estos samplers se pueden utilizar para generar texto con modelos personalizados.\n\n","metadata":{"id":"wh2N8PNzzb74","papermill":{"duration":0.010576,"end_time":"2023-08-06T00:20:37.635728","exception":false,"start_time":"2023-08-06T00:20:37.625152","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Cargamos un modelo pre-entrenado de GPT-2 y generamos texto\n\nKerasNLP proporciona varios modelos pre-entrenados, como [Google\nBert](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)\ny [GPT-2](https://openai.com/research/better-language-models). Puedes ver\nla lista de modelos disponibles en el [repositorio de KerasNLP](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/models).\n\nEs muy fácil cargar el modelo GPT-2, como puedes ver a continuación:","metadata":{"id":"YieMpyQEzb75","papermill":{"duration":0.010668,"end_time":"2023-08-06T00:20:37.657396","exception":false,"start_time":"2023-08-06T00:20:37.646728","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Para acelerar el entrenamiento y la generación, utilizamos un preprocesador\n# de longitud 128 en lugar de la longitud completa de 1024.\n\npreprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n    \"gpt2_base_en\",\n    sequence_length=128,\n)\ngpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n    \"gpt2_base_en\", preprocessor=preprocessor\n)","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:20:37.682736Z","iopub.status.busy":"2023-08-06T00:20:37.680537Z","iopub.status.idle":"2023-08-06T00:20:54.999722Z","shell.execute_reply":"2023-08-06T00:20:54.998705Z"},"id":"_5HgQlt-zb75","outputId":"03b0e6a9-0e49-46bd-a96e-9da21640a52c","papermill":{"duration":17.333867,"end_time":"2023-08-06T00:20:55.002154","exception":false,"start_time":"2023-08-06T00:20:37.668287","status":"completed"},"tags":[]},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/vocab.json\n\n1042301/1042301 [==============================] - 0s 0us/step\n\nDownloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/merges.txt\n\n456318/456318 [==============================] - 0s 0us/step\n\nDownloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/model.h5\n\n497986112/497986112 [==============================] - 3s 0us/step\n"}]},{"cell_type":"markdown","source":"Una vez que el modelo está cargado, puedes usarlo para generar texto de inmediato. Ejecuta las celdas a continuación para probarlo. Es tan simple como llamar a la función generate() una sola vez.","metadata":{"id":"ki5OKmgRzb76","papermill":{"duration":0.015243,"end_time":"2023-08-06T00:20:55.033511","exception":false,"start_time":"2023-08-06T00:20:55.018268","status":"completed"},"tags":[]}},{"cell_type":"code","source":"start = time.time()\n\noutput = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\nprint(\"\\nGPT-2 output:\")\nprint(output)\n\nend = time.time()\nprint(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:20:55.066337Z","iopub.status.busy":"2023-08-06T00:20:55.066021Z","iopub.status.idle":"2023-08-06T00:21:23.467588Z","shell.execute_reply":"2023-08-06T00:21:23.466465Z"},"id":"Khn7wneEzb76","outputId":"ba160caa-60b3-4e51-f5ff-26f748c7f681","papermill":{"duration":28.42098,"end_time":"2023-08-06T00:21:23.469746","exception":false,"start_time":"2023-08-06T00:20:55.048766","status":"completed"},"tags":[]},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\nGPT-2 output:\n\nMy trip to Yosemite was a little over two years ago. I spent the last three years in Yosemite National Park, hiking and camping, visiting many great places in the region. I was fortunate to meet and enjoy a number of great local attractions including the Yosemite National Park, the Yosemite National Park Zoo, the Yosemite National Park Zoo, Yosemite National Park's Grand Canyon, Yosemite National Park Zoo, Yosemite National Park's Yosemite National Park Zoo, and Yosemite's Great White Shark. The last time I visited Yosemite I went with my family, but it wasn't until I went to Yosemite's Big Blue Lodge that I realized I could enjoy the beauty of the park.\n\n\n\nMy experience with Yosemite is a little more personal, but I hope that I've shown you that there's a lot to enjoy in Yosemite. I love Yosemite because it is a place of true adventure. It has a beautiful view of the entire region. I also like the views that the Grand Canyon has. I love the view of\n\nTOTAL TIME ELAPSED: 28.39s\n"}]},{"cell_type":"markdown","source":"Intenta con otro ejemplo:","metadata":{"id":"hUhMT575zb76","papermill":{"duration":0.015241,"end_time":"2023-08-06T00:21:23.500815","exception":false,"start_time":"2023-08-06T00:21:23.485574","status":"completed"},"tags":[]}},{"cell_type":"code","source":"start = time.time()\n\noutput = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\nprint(\"\\nGPT-2 output:\")\nprint(output)\n\nend = time.time()\nprint(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:21:23.533102Z","iopub.status.busy":"2023-08-06T00:21:23.532796Z","iopub.status.idle":"2023-08-06T00:21:25.309780Z","shell.execute_reply":"2023-08-06T00:21:25.308686Z"},"id":"AlORlhDwzb76","outputId":"3f18305b-c7f1-466c-960b-c408839264ef","papermill":{"duration":1.796068,"end_time":"2023-08-06T00:21:25.312101","exception":false,"start_time":"2023-08-06T00:21:23.516033","status":"completed"},"tags":[]},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\nGPT-2 output:\n\nThat Italian restaurant is now closed. The owner says it's because he doesn't have any money to pay staff. He says it was just because he was a \"bad person\" and that his employees are \"a bunch of idiots who are not paying their bills.\"\n\n\n\nBut the restaurateur says that's not the case.\n\n\n\n\"I am not a person who wants to be a bad person,\" he said. \"It is my right. If someone wants to be a bad person, I am the person.\"\n\n\n\nThe restaurant's manager, who asked not to be named because he's not authorized to speak to the media, says the restaurant will be closing.\n\n\n\n\"It's just a sad story,\" she said. \"We have a lot to do to help people. We have a great restaurant and we're very proud to have a great customer base.\"\n\n\n\nThe restaurant was open for about two weeks last week, according to the restaurant's website. But after\n\nTOTAL TIME ELAPSED: 1.77s\n"}]},{"cell_type":"markdown","source":"Observa cuán más rápido es el segundo llamado. Esto se debe a que el grafo computacional se compila con [XLA](https://www.tensorflow.org/xla) en la primera ejecución y se reutiliza en la segunda, en segundo plano.\n\nLa calidad del texto generado parece estar bien, pero podemos mejorarlo mediante el ajuste fino / afinación (fine-tuning.).","metadata":{"id":"GDdFVHsCzb76","papermill":{"duration":0.015987,"end_time":"2023-08-06T00:21:25.346234","exception":false,"start_time":"2023-08-06T00:21:25.330247","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Más sobre el modelo GPT-2 de KerasNLP\n\nA continuación, vamos a ajustar finamente el modelo para actualizar sus parámetros, pero antes de hacerlo, echemos un vistazo al conjunto completo de herramientas que tenemos para trabajar con GPT2.\n\nEl código de GPT2 se puede encontrar [aquí](https://github.com/keras-team/keras-nlp/blob/master/keras_nlp/models/gpt2/). Conceptualmente, `GPT2CausalLM` se puede descomponer jerárquicamente en varios módulos en KerasNLP, todos los cuales tienen una función *from_preset()* que carga un modelo pre-entrenado:\n\n- `keras_nlp.models.GPT2Tokenizer`: El tokenizador utilizado por el modelo GPT2, que es un [codificador de pares de bytes](https://huggingface.co/course/chapter6/5?fw=pt).\n- `keras_nlp.models.GPT2CausalLMPreprocessor`: el preprocesador utilizado en el entrenamiento causal de GPT2. Realiza la tokenización junto con otros trabajos de preprocesamiento, como la creación de la etiqueta y la adición del token de finalización.\n- `keras_nlp.models.GPT2Backbone`: el modelo GPT2, que es una pila de `keras_nlp.layers.TransformerDecoder`. A esto generalmente se le denomina simplemente `GPT2`.\n- `keras_nlp.models.GPT2CausalLM`: envuelve a `GPT2Backbone`, multiplica la salida de `GPT2Backbone` por la matriz de embedding para generar logits sobre los tokens del vocabulario.","metadata":{"id":"DMUG5tCvzb76","papermill":{"duration":0.016104,"end_time":"2023-08-06T00:21:25.378110","exception":false,"start_time":"2023-08-06T00:21:25.362006","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Ajuste fino (Fine-tuning) en el conjunto de datos WikiHow\n\nAhora que tienes conocimientos sobre el modelo GPT-2 de KerasNLP, puedes dar un paso más para ajustar finamente el modelo y lograr que genere texto en un estilo específico, ya sea corto o largo, formal o casual. En este tutorial, utilizaremos el conjunto de datos de Wikihow como ejemplo.\n\n\n\n## Fine-tuning con el Dataset en Español\n\nTambién podemos ajustar finamente GPT2 en conjuntos de datos que no sean su idioma principal de entrenamiento. Esta parte muestra cómo ajustar finamente GPT2 en un conjunto de datos de wikihow en español para enseñar a nuestro modelo a convertirse en un sabelotodo.\n\nDebido a que GPT2 utiliza un codificador de pares de bytes (byte-pair encoder) y el conjunto de datos de pre-entrenamiento original contiene algunos caracteres de gran parte de idiomas, podemos utilizar el vocabulario original para ajustar finamente en un conjunto de datos en español.","metadata":{"id":"mKGfUONezb77","papermill":{"duration":0.015272,"end_time":"2023-08-06T00:21:25.409439","exception":false,"start_time":"2023-08-06T00:21:25.394167","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!# Descargamos el dataset desde HuggingFace\n!git clone https://huggingface.co/datasets/daqc/wikihow-spanish","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:21:25.445995Z","iopub.status.busy":"2023-08-06T00:21:25.445568Z","iopub.status.idle":"2023-08-06T00:21:32.130283Z","shell.execute_reply":"2023-08-06T00:21:32.129105Z"},"id":"Ct1gnrN5zb77","outputId":"9c0e410d-83ed-4bcf-ca98-37f0cee7a1d3","papermill":{"duration":6.706059,"end_time":"2023-08-06T00:21:32.133041","exception":false,"start_time":"2023-08-06T00:21:25.426982","status":"completed"},"tags":[]},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"Cloning into 'wikihow-spanish'...\n\nremote: Enumerating objects: 14, done.\u001b[K\n\nremote: Total 14 (delta 0), reused 0 (delta 0), pack-reused 14\u001b[K\n\nUnpacking objects: 100% (14/14), 2.54 KiB | 651.00 KiB/s, done.\n"}]},{"cell_type":"markdown","source":"Echemos un vistazo dentro de los datos de muestra del conjunto de datos:\n","metadata":{"id":"RhQKRjNBzb77","papermill":{"duration":0.015507,"end_time":"2023-08-06T00:21:32.166459","exception":false,"start_time":"2023-08-06T00:21:32.150952","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import json\n\n# Leer el archivo JSON\nwith open('wikihow-spanish/spanish.json', 'r') as file:\n    data = json.load(file)\n\n# Obtener la primera clave y el primer elemento del diccionario\nprimer_clave = next(iter(data))\nprimer_elemento = data[primer_clave]\n\n# Imprimir la clave y la estructura del primer elemento\nprint(\"Clave:\", primer_clave)\nprint(\"Estructura:\")\nprint(json.dumps(primer_elemento, indent=4))","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:21:32.200055Z","iopub.status.busy":"2023-08-06T00:21:32.199686Z","iopub.status.idle":"2023-08-06T00:21:38.170530Z","shell.execute_reply":"2023-08-06T00:21:38.169584Z"},"id":"t1ATVaVJzb77","outputId":"3f509407-b00a-4f9e-d421-c99184cfb413","papermill":{"duration":5.991953,"end_time":"2023-08-06T00:21:38.173906","exception":false,"start_time":"2023-08-06T00:21:32.181953","status":"completed"},"tags":[]},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"Clave: https://es.wikihow.com/calcular-el-rendimiento-anualizado-de-una-cartera-de-inversiones\n\nEstructura:\n\n{\n\n    \"Calcular tu rendimiento anualizado\": {\n\n        \"summary\": \"Calcula tu rendimiento anualizado. Calcula el rendimiento semestral. Calcula un equivalente anualizado.\",\n\n        \"document\": \"Una vez que hayas calculado el rendimiento total (como se muestra arriba), ingresa el resultado en esta ecuaci\\u00f3n: rendimiento anualizado = (1+ rendimiento)1/N-1 El producto de esta ecuaci\\u00f3n ser\\u00e1 el n\\u00famero correspondiente al rendimiento de cada a\\u00f1o durante todo el periodo de tiempo.  En el exponente (el n\\u00famero peque\\u00f1o que est\\u00e1 afuera del par\\u00e9ntesis), el \\u201c1\\u201d representa la unidad que estamos midiendo, que es un a\\u00f1o. Si deseas ser m\\u00e1s espec\\u00edfico, podr\\u00edas usar \\u201c365\\u201d para obtener el rendimiento diario. La \\u201cN\\u201d representa el n\\u00famero de periodos que medir\\u00e1s. Entonces, si mides tu rendimiento en 7 a\\u00f1os, tendr\\u00e1s que utilizar este n\\u00famero en lugar de \\\"N\\\". Por ejemplo, supongamos que en un periodo de siete a\\u00f1os, el valor de tu cartera creci\\u00f3 de $1,000 a $2,500. Primero calcula tu rendimiento total: (2 500-1 000)/1000 = 1,50 (un rendimiento de 150\\u00a0%). El siguiente paso es calcular tu rendimiento anualizado: (1 + 1,50)1/7-1 = 0,1399 = 13,99\\u00a0% de rendimiento anual. \\u00a1Eso es todo! Respeta el orden matem\\u00e1tico normal que se utiliza para resolver operaciones: primero haz las que est\\u00e1n adentro de los par\\u00e9ntesis, despu\\u00e9s aplica el exponente y luego realiza la sustracci\\u00f3n. Ahora bien, digamos que quieres saber cu\\u00e1l es el rendimiento semestral (el que se obtiene dos veces al a\\u00f1o, es decir cada seis meses) en el transcurso de este periodo de siete a\\u00f1os.  La f\\u00f3rmula sigue siendo la misma, solo tendr\\u00e1s que modificar el n\\u00famero de periodos que vas a calcular. El resultado final ser\\u00e1 tu rendimiento semestral.  En este caso, tendr\\u00e1s 14 periodos semestrales, dos en cada a\\u00f1o durante los siete. Primero calcula el rendimiento total: (2 500-1 000)/1000 = 1,50 (un rendimiento de 150\\u00a0%). Despu\\u00e9s calcula tu rendimiento anualizado: (1 + 1,50)1/14-1 = 6,76\\u00a0%. Puedes convertir este resultado a un rendimiento anual simplemente al multiplicarlo por 2: 6,76\\u00a0% x 2 = 13,52\\u00a0%. Tambi\\u00e9n puedes calcular el equivalente anualizado de rendimientos en periodos m\\u00e1s cortos. Por ejemplo, imagina que solo obtuviste un rendimiento de seis meses y quieres saber su equivalente anualizado. Nuevamente, la f\\u00f3rmula es la misma.  Supongamos que en un periodo de seis meses, el valor de tu cartera se incrementa de $1 000 a $1 050. Empieza con el c\\u00e1lculo de tu rendimiento total: (1 050-1 000)/1 000= 0,05 (un rendimiento del 5\\u00a0% en seis meses). Ahora bien, si quisieras saber cu\\u00e1l ser\\u00eda el equivalente anualizado (asumiendo que la tasa de rendimiento y el rendimiento compuesto se mantengan),  tendr\\u00e1s que hacer el siguiente c\\u00e1lculo: (1+0,05)1/0,50-1=10,25\\u00a0% de rendimiento anual. Sin importar cu\\u00e1n largo o corto sea el periodo de tiempo, si sigues la f\\u00f3rmula de arriba, siempre podr\\u00e1s convertir tu rendimiento a uno anualizado.\",\n\n        \"english_section_name\": \"Calculating Your Annualized Return\",\n\n        \"english_url\": \"https://www.wikihow.com/Calculate-Annualized-Portfolio-Return\"\n\n    },\n\n    \"Sentar los fundamentos\": {\n\n        \"summary\": \"Aprende los t\\u00e9rminos claves. Aprende c\\u00f3mo funciona el rendimiento compuesto. Utiliza un rendimiento ponderado en el tiempo para calcular tu tasa compuesta de rendimiento. Calcula tu rendimiento total. Aprende cu\\u00e1les son las f\\u00f3rmulas de Excel para estos c\\u00e1lculos.\",\n\n        \"document\": \"Al discutir el rendimiento anualizado de una cartera de inversiones, hay varios t\\u00e9rminos esenciales que aparecer\\u00e1n continuamente y que es importante que entiendas. Estos son los siguientes:  El rendimiento anual: este es el rendimiento total de una inversi\\u00f3n en un periodo de un a\\u00f1o civil, en el que se incluyen los dividendos, los intereses y las ganancias del capital.   El rendimiento anualizado: la tasa anual de rendimiento que se infiere al extrapolar el rendimiento que se mide en periodos m\\u00e1s cortos o largos que un a\\u00f1o civil.   El rendimiento promedio: es el rendimiento normal que se obtiene en un periodo de tiempo y que se calcula al separar lo obtenido en un tiempo largo en partes iguales, de acuerdo a los periodos (m\\u00e1s cortos).   Rendimiento compuesto (o capitalizado): este incluye los resultados de la reinversi\\u00f3n de intereses, dividendos y ganancias del capital.   Periodo: una duraci\\u00f3n espec\\u00edfica de tiempo seleccionado para medir y calcular el rendimiento, puede ser diaria, mensual, trimestral o anualmente. Rendimiento peri\\u00f3dico: el rendimiento total de una inversi\\u00f3n medido en un periodo de tiempo espec\\u00edfico. Este es el crecimiento de las ganancias que ya has adquirido. Mientras tu dinero se capitalice por m\\u00e1s tiempo, este crecer\\u00e1 m\\u00e1s r\\u00e1pido y mayor ser\\u00e1 tu rendimiento anualizado. Por ejemplo, piensa en una bola de nieve que rueda cuesta abajo y que va creciendo conforme avanza con mayor rapidez.  Digamos que inviertes $100 y ganas el 100\\u00a0% en tu primer a\\u00f1o, lo que te resulta en $200 al final de dicho periodo de tiempo. Si obtuvieras solo el 10\\u00a0% en el segundo a\\u00f1o, ganar\\u00edas $20 por tus $200 al t\\u00e9rmino del segundo a\\u00f1o. Sin embargo, digamos que hubieras ganado solo el 50\\u00a0% durante el primer a\\u00f1o, tendr\\u00edas $150 al inicio del segundo. Esa misma ganancia del 10\\u00a0% en el segundo a\\u00f1o te dar\\u00eda $15 en lugar de 20. Esto representa un 33\\u00a0% menos que los $20 que hubieras podido ganar en el caso del primer ejemplo. Para ilustrar mejor el concepto, digamos que has perdido el 50\\u00a0% en el primer a\\u00f1o, lo que te deja con solo $50. Entonces, tendr\\u00e1s que ganar el 100\\u00a0% solo para volver a tener la cantidad inicial (100\\u00a0% de $50 = $50, y $50 + $50 = $100). La dimensi\\u00f3n de las ganancias y el tiempo en el que ocurren juegan un rol muy importante al momento de explicar el rendimiento compuesto y su efecto en el rendimiento anualizado. En otras palabras, este \\u00faltimo no es una manera confiable de medir las ganancias o las p\\u00e9rdidas. Sin embargo, constituye una buena herramienta al momento de comparar varias inversiones con otras. Cuando quieres encontrar el promedio de varias cosas, como la precipitaci\\u00f3n diaria o la p\\u00e9rdida de peso en varios meses, con frecuencia puedes usar un promedio simple o una media aritm\\u00e9tica. Esta es una t\\u00e9cnica que probablemente aprendiste en la escuela. No obstante, el promedio simple no explica los efectos que cada rendimiento peri\\u00f3dico tiene en los otros o el tiempo de cada uno. Para lograrlo, se puede utilizar un rendimiento geom\\u00e9trico ponderado en el tiempo. \\u00a1No te preocupes, este art\\u00edculo te guiar\\u00e1 para realizar la f\\u00f3rmula!  Un promedio simple no funciona porque todos los rendimientos peri\\u00f3dicos dependen de los dem\\u00e1s.   Por ejemplo, imagina que quieres tabular el rendimiento promedio de $100 en dos a\\u00f1o. Digamos que hayas ganado el 100\\u00a0% en el primer a\\u00f1o, lo que significa que tendr\\u00edas $200 al final (100\\u00a0% de 100 = 100). Si perdieras 50\\u00a0% durante el segundo a\\u00f1o, tendr\\u00edas $100 al final de \\u00e9l (50\\u00a0% de 200 = 100). Esta es la misma cantidad con la que empezaste al principio del primer a\\u00f1o. Un promedio simple (media aritm\\u00e9tica) sumar\\u00eda los dos resultados y los dividir\\u00eda entre el n\\u00famero de periodos, que en el ejemplo son dos a\\u00f1os. El resultado te har\\u00eda creer que ganaste un rendimiento promedio de 25% cada a\\u00f1o. Sin embargo, cuando relacionas los dos rendimientos, te podr\\u00e1s dar cuenta que en realidad no ganaste nada. Los a\\u00f1os se neutralizan entre ellos. Para comenzar, debes calcular el rendimiento total en todo el periodo de tiempo que est\\u00e1s evaluando. Para una mayor claridad, utilizaremos un ejemplo en el que no se realizar\\u00e1n dep\\u00f3sitos ni retiros. Si quieres calcular tu rendimiento total, lo \\u00fanico que necesitas son dos n\\u00fameros: el valor inicial de la cartera de inversiones y el final.  Sustrae el valor inicial del final. Divide este n\\u00famero entre el valor inicial. El resultado ser\\u00e1 tu rendimiento. En el caso de que se d\\u00e9 una p\\u00e9rdida durante el periodo evaluado, debes sustraer el balance final del inicial. Despu\\u00e9s, divide el resultado entre el inicial y considera al producto como un valor negativo. Esta \\u00faltima operaci\\u00f3n sustituye la necesidad de sumar algebraicamente un n\\u00famero negativo.   Realiza primero la sustracci\\u00f3n, luego la divisi\\u00f3n. Estas operaciones te dar\\u00e1n tu porcentaje total de rendimiento. La f\\u00f3rmula para la tasa de rendimiento total es la siguiente: (valor final de la cartera - valor inicial de la cartera)/valor inicial de la cartera. La f\\u00f3rmula para obtener la tasa compuesta de rendimiento es: POWER((1 + tasa de rendimiento total),(1/a\\u00f1os))-1. Por ejemplo, si el valor inicial de la cartera de inversiones fuera de $1 000 y su valor final fuera de $2 500, siete a\\u00f1os despu\\u00e9s, los c\\u00e1lculos ser\\u00edan los siguientes:  Tasa de rendimiento total = (2 500-1 000)/1 000 = 1,5. Tasa compuesta de rendimiento= POWER((1 + 1,5),(1/7)) - 1 = 0,1398 = 13,98\\u00a0%.\",\n\n        \"english_section_name\": \"Laying the Groundwork\",\n\n        \"english_url\": \"https://www.wikihow.com/Calculate-Annualized-Portfolio-Return\"\n\n    }\n\n}\n"}]},{"cell_type":"markdown","source":"En nuestro caso, al realizar la predicción de la siguiente palabra en un modelo de lenguaje, necesitamos obtener solamente la informacion de relevancia del dataset mediante el siguiente codigo:","metadata":{"id":"NDhxryFVzb77","papermill":{"duration":0.017019,"end_time":"2023-08-06T00:21:38.207807","exception":false,"start_time":"2023-08-06T00:21:38.190788","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport json\nfrom urllib.parse import urlsplit, unquote\n\nwikihow_data = []\nfor file in os.listdir(\"wikihow-spanish/\"):\n    if \".json\" not in file:\n        continue\n    full_filename = os.path.join(\"wikihow-spanish/\", file)\n    with open(full_filename, \"r\") as f:\n        content = json.load(f)\n        wikihow_data.append(content)\n\nparagraphs = []\nfor parent_url, sections in data.items():\n    decoded_parent_url = \"¿Cómo \" + unquote(urlsplit(parent_url).path.split(\"/\")[-1]).replace('-', ' ') + \"?\"\n    paragraph = f\"{decoded_parent_url}\\n\"\n    for section in sections:\n        section_data = sections[section]\n        title = section + \":\"\n        summary = section_data.get(\"summary\", \"\")\n        document = section_data.get(\"document\", \"\")\n        paragraph += f\"{title}\\n{summary}\\n{document}\\n\"\n    paragraphs.append(paragraph)","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:21:38.242026Z","iopub.status.busy":"2023-08-06T00:21:38.241688Z","iopub.status.idle":"2023-08-06T00:21:45.241002Z","shell.execute_reply":"2023-08-06T00:21:45.239868Z"},"papermill":{"duration":7.019265,"end_time":"2023-08-06T00:21:45.243621","exception":false,"start_time":"2023-08-06T00:21:38.224356","status":"completed"},"tags":[]},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Damos un vistazo a los datos de ejemplo.","metadata":{"id":"KbIH0qeUaRIg","papermill":{"duration":0.016279,"end_time":"2023-08-06T00:21:45.277192","exception":false,"start_time":"2023-08-06T00:21:45.260913","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"Parrafo 1:\")\nprint(paragraphs[0])\n#print(\"Parrafo 2:\")\n#print(paragraphs[1])","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:21:45.312483Z","iopub.status.busy":"2023-08-06T00:21:45.310918Z","iopub.status.idle":"2023-08-06T00:21:45.318529Z","shell.execute_reply":"2023-08-06T00:21:45.316815Z"},"id":"tsUmonjoaQwb","outputId":"c1d1c76d-d305-414d-ca38-354e6ada3802","papermill":{"duration":0.027334,"end_time":"2023-08-06T00:21:45.320941","exception":false,"start_time":"2023-08-06T00:21:45.293607","status":"completed"},"tags":[]},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"Parrafo 1:\n\n¿Cómo calcular el rendimiento anualizado de una cartera de inversiones?\n\nCalcular tu rendimiento anualizado:\n\nCalcula tu rendimiento anualizado. Calcula el rendimiento semestral. Calcula un equivalente anualizado.\n\nUna vez que hayas calculado el rendimiento total (como se muestra arriba), ingresa el resultado en esta ecuación: rendimiento anualizado = (1+ rendimiento)1/N-1 El producto de esta ecuación será el número correspondiente al rendimiento de cada año durante todo el periodo de tiempo.  En el exponente (el número pequeño que está afuera del paréntesis), el “1” representa la unidad que estamos midiendo, que es un año. Si deseas ser más específico, podrías usar “365” para obtener el rendimiento diario. La “N” representa el número de periodos que medirás. Entonces, si mides tu rendimiento en 7 años, tendrás que utilizar este número en lugar de \"N\". Por ejemplo, supongamos que en un periodo de siete años, el valor de tu cartera creció de $1,000 a $2,500. Primero calcula tu rendimiento total: (2 500-1 000)/1000 = 1,50 (un rendimiento de 150 %). El siguiente paso es calcular tu rendimiento anualizado: (1 + 1,50)1/7-1 = 0,1399 = 13,99 % de rendimiento anual. ¡Eso es todo! Respeta el orden matemático normal que se utiliza para resolver operaciones: primero haz las que están adentro de los paréntesis, después aplica el exponente y luego realiza la sustracción. Ahora bien, digamos que quieres saber cuál es el rendimiento semestral (el que se obtiene dos veces al año, es decir cada seis meses) en el transcurso de este periodo de siete años.  La fórmula sigue siendo la misma, solo tendrás que modificar el número de periodos que vas a calcular. El resultado final será tu rendimiento semestral.  En este caso, tendrás 14 periodos semestrales, dos en cada año durante los siete. Primero calcula el rendimiento total: (2 500-1 000)/1000 = 1,50 (un rendimiento de 150 %). Después calcula tu rendimiento anualizado: (1 + 1,50)1/14-1 = 6,76 %. Puedes convertir este resultado a un rendimiento anual simplemente al multiplicarlo por 2: 6,76 % x 2 = 13,52 %. También puedes calcular el equivalente anualizado de rendimientos en periodos más cortos. Por ejemplo, imagina que solo obtuviste un rendimiento de seis meses y quieres saber su equivalente anualizado. Nuevamente, la fórmula es la misma.  Supongamos que en un periodo de seis meses, el valor de tu cartera se incrementa de $1 000 a $1 050. Empieza con el cálculo de tu rendimiento total: (1 050-1 000)/1 000= 0,05 (un rendimiento del 5 % en seis meses). Ahora bien, si quisieras saber cuál sería el equivalente anualizado (asumiendo que la tasa de rendimiento y el rendimiento compuesto se mantengan),  tendrás que hacer el siguiente cálculo: (1+0,05)1/0,50-1=10,25 % de rendimiento anual. Sin importar cuán largo o corto sea el periodo de tiempo, si sigues la fórmula de arriba, siempre podrás convertir tu rendimiento a uno anualizado.\n\nSentar los fundamentos:\n\nAprende los términos claves. Aprende cómo funciona el rendimiento compuesto. Utiliza un rendimiento ponderado en el tiempo para calcular tu tasa compuesta de rendimiento. Calcula tu rendimiento total. Aprende cuáles son las fórmulas de Excel para estos cálculos.\n\nAl discutir el rendimiento anualizado de una cartera de inversiones, hay varios términos esenciales que aparecerán continuamente y que es importante que entiendas. Estos son los siguientes:  El rendimiento anual: este es el rendimiento total de una inversión en un periodo de un año civil, en el que se incluyen los dividendos, los intereses y las ganancias del capital.   El rendimiento anualizado: la tasa anual de rendimiento que se infiere al extrapolar el rendimiento que se mide en periodos más cortos o largos que un año civil.   El rendimiento promedio: es el rendimiento normal que se obtiene en un periodo de tiempo y que se calcula al separar lo obtenido en un tiempo largo en partes iguales, de acuerdo a los periodos (más cortos).   Rendimiento compuesto (o capitalizado): este incluye los resultados de la reinversión de intereses, dividendos y ganancias del capital.   Periodo: una duración específica de tiempo seleccionado para medir y calcular el rendimiento, puede ser diaria, mensual, trimestral o anualmente. Rendimiento periódico: el rendimiento total de una inversión medido en un periodo de tiempo específico. Este es el crecimiento de las ganancias que ya has adquirido. Mientras tu dinero se capitalice por más tiempo, este crecerá más rápido y mayor será tu rendimiento anualizado. Por ejemplo, piensa en una bola de nieve que rueda cuesta abajo y que va creciendo conforme avanza con mayor rapidez.  Digamos que inviertes $100 y ganas el 100 % en tu primer año, lo que te resulta en $200 al final de dicho periodo de tiempo. Si obtuvieras solo el 10 % en el segundo año, ganarías $20 por tus $200 al término del segundo año. Sin embargo, digamos que hubieras ganado solo el 50 % durante el primer año, tendrías $150 al inicio del segundo. Esa misma ganancia del 10 % en el segundo año te daría $15 en lugar de 20. Esto representa un 33 % menos que los $20 que hubieras podido ganar en el caso del primer ejemplo. Para ilustrar mejor el concepto, digamos que has perdido el 50 % en el primer año, lo que te deja con solo $50. Entonces, tendrás que ganar el 100 % solo para volver a tener la cantidad inicial (100 % de $50 = $50, y $50 + $50 = $100). La dimensión de las ganancias y el tiempo en el que ocurren juegan un rol muy importante al momento de explicar el rendimiento compuesto y su efecto en el rendimiento anualizado. En otras palabras, este último no es una manera confiable de medir las ganancias o las pérdidas. Sin embargo, constituye una buena herramienta al momento de comparar varias inversiones con otras. Cuando quieres encontrar el promedio de varias cosas, como la precipitación diaria o la pérdida de peso en varios meses, con frecuencia puedes usar un promedio simple o una media aritmética. Esta es una técnica que probablemente aprendiste en la escuela. No obstante, el promedio simple no explica los efectos que cada rendimiento periódico tiene en los otros o el tiempo de cada uno. Para lograrlo, se puede utilizar un rendimiento geométrico ponderado en el tiempo. ¡No te preocupes, este artículo te guiará para realizar la fórmula!  Un promedio simple no funciona porque todos los rendimientos periódicos dependen de los demás.   Por ejemplo, imagina que quieres tabular el rendimiento promedio de $100 en dos año. Digamos que hayas ganado el 100 % en el primer año, lo que significa que tendrías $200 al final (100 % de 100 = 100). Si perdieras 50 % durante el segundo año, tendrías $100 al final de él (50 % de 200 = 100). Esta es la misma cantidad con la que empezaste al principio del primer año. Un promedio simple (media aritmética) sumaría los dos resultados y los dividiría entre el número de periodos, que en el ejemplo son dos años. El resultado te haría creer que ganaste un rendimiento promedio de 25% cada año. Sin embargo, cuando relacionas los dos rendimientos, te podrás dar cuenta que en realidad no ganaste nada. Los años se neutralizan entre ellos. Para comenzar, debes calcular el rendimiento total en todo el periodo de tiempo que estás evaluando. Para una mayor claridad, utilizaremos un ejemplo en el que no se realizarán depósitos ni retiros. Si quieres calcular tu rendimiento total, lo único que necesitas son dos números: el valor inicial de la cartera de inversiones y el final.  Sustrae el valor inicial del final. Divide este número entre el valor inicial. El resultado será tu rendimiento. En el caso de que se dé una pérdida durante el periodo evaluado, debes sustraer el balance final del inicial. Después, divide el resultado entre el inicial y considera al producto como un valor negativo. Esta última operación sustituye la necesidad de sumar algebraicamente un número negativo.   Realiza primero la sustracción, luego la división. Estas operaciones te darán tu porcentaje total de rendimiento. La fórmula para la tasa de rendimiento total es la siguiente: (valor final de la cartera - valor inicial de la cartera)/valor inicial de la cartera. La fórmula para obtener la tasa compuesta de rendimiento es: POWER((1 + tasa de rendimiento total),(1/años))-1. Por ejemplo, si el valor inicial de la cartera de inversiones fuera de $1 000 y su valor final fuera de $2 500, siete años después, los cálculos serían los siguientes:  Tasa de rendimiento total = (2 500-1 000)/1 000 = 1,5. Tasa compuesta de rendimiento= POWER((1 + 1,5),(1/7)) - 1 = 0,1398 = 13,98 %.\n\n\n"}]},{"cell_type":"markdown","source":"Ahora puedes realizar el proceso de fine-tuning del modelo usando la función *fit()* que ya conoces. Ten en cuenta que el `preprocessor` se llamará automáticamente dentro del método `fit` ya que `GPT2CausalLM` es una instancia de `keras_nlp.models.Task`.\n\nEste paso requiere bastante memoria de la GPU y mucho tiempo si quisiéramos entrenarlo hasta alcanzar un estado completamente entrenado. En este caso, solo utilizamos una parte del conjunto de datos con fines de demostración.","metadata":{"id":"9wkh--Eazb77","papermill":{"duration":0.016383,"end_time":"2023-08-06T00:21:45.353632","exception":false,"start_time":"2023-08-06T00:21:45.337249","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nimport tensorflow.keras as keras\nimport os\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow.keras.callbacks as callbacks\n\n# Preparar el conjunto de datos\ntrain_ds = (\n    tf.data.Dataset.from_tensor_slices(paragraphs)\n    .batch(16)\n    .cache()\n    .prefetch(tf.data.AUTOTUNE)\n)\n\n# Definir el número de épocas a 1 para demostración\nnum_epochs = 10\n# Recorrer todo el conjunto de datos lleva mucho tiempo, solo tomemos `500`\n# train_ds = train_ds.take(500)\n\n\n# Calcular el tamaño para el conjunto de validación (20% del dataset de entrenamiento)\nval_size = int(0.2 * len(paragraphs))\n\n# Dividir el conjunto de datos de entrenamiento en entrenamiento y validación\nval_ds = train_ds.take(val_size)\n\n\nlearning_rate = keras.optimizers.schedules.PolynomialDecay(\n    5e-4,\n    decay_steps=train_ds.cardinality() * num_epochs,\n    end_learning_rate=0.0,\n)\n\nloss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\ngpt2_lm.compile(\n    optimizer=keras.optimizers.Adam(learning_rate),\n    loss=loss,\n    weighted_metrics=[\"accuracy\"],  # Agregar 'mean_squared_error' y cualquier otra métrica que desees\n)\n\n# Directorio para guardar los checkpoints\ncheckpoint_dir = \"checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n# Callback para guardar checkpoints por epoch\ncheckpoint_callback = ModelCheckpoint(\n    filepath=os.path.join(checkpoint_dir, \"model_{epoch:02d}.ckpt\"),\n    save_freq=\"epoch\",\n    save_weights_only=True,\n    save_best_only=False,\n    verbose=1\n)\n\n\n# Callback personalizado para obtener el tiempo por época y tiempo acumulado\nclass TimeHistory(callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n        self.start_time = time.time()\n\n    def on_epoch_end(self, batch, logs={}):\n        self.times.append(time.time() - self.start_time)\n        self.start_time = time.time()\n\n# Crear el callback para obtener el tiempo por época y tiempo acumulado\ntime_callback = TimeHistory()\n\n# Entrenar el modelo\nhistory = gpt2_lm.fit(train_ds, epochs=num_epochs, validation_data=val_ds, callbacks=[checkpoint_callback, time_callback])\n","metadata":{"execution":{"iopub.execute_input":"2023-08-06T00:21:45.388246Z","iopub.status.busy":"2023-08-06T00:21:45.387963Z","iopub.status.idle":"2023-08-06T05:14:52.118532Z","shell.execute_reply":"2023-08-06T05:14:52.117316Z"},"id":"me-ggq_Tzb77","outputId":"3e93cb1c-bab1-4577-95b3-bb2e51244239","papermill":{"duration":17586.754456,"end_time":"2023-08-06T05:14:52.124814","exception":false,"start_time":"2023-08-06T00:21:45.370358","status":"completed"},"tags":[]},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 2.3361 - accuracy: 0.5358\n\nEpoch 1: saving model to checkpoints/model_01.ckpt\n\n2425/2425 [==============================] - 1849s 736ms/step - loss: 2.3361 - accuracy: 0.5358 - val_loss: 1.8612 - val_accuracy: 0.6025\n\nEpoch 2/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.8795 - accuracy: 0.5982\n\nEpoch 2: saving model to checkpoints/model_02.ckpt\n\n2425/2425 [==============================] - 1707s 704ms/step - loss: 1.8795 - accuracy: 0.5982 - val_loss: 1.6312 - val_accuracy: 0.6364\n\nEpoch 3/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.6922 - accuracy: 0.6256\n\nEpoch 3: saving model to checkpoints/model_03.ckpt\n\n2425/2425 [==============================] - 1703s 702ms/step - loss: 1.6922 - accuracy: 0.6256 - val_loss: 1.4751 - val_accuracy: 0.6606\n\nEpoch 4/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.5477 - accuracy: 0.6477\n\nEpoch 4: saving model to checkpoints/model_04.ckpt\n\n2425/2425 [==============================] - 1754s 723ms/step - loss: 1.5477 - accuracy: 0.6477 - val_loss: 1.3360 - val_accuracy: 0.6844\n\nEpoch 5/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.4221 - accuracy: 0.6681\n\nEpoch 5: saving model to checkpoints/model_05.ckpt\n\n2425/2425 [==============================] - 1712s 706ms/step - loss: 1.4221 - accuracy: 0.6681 - val_loss: 1.2109 - val_accuracy: 0.7070\n\nEpoch 6/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.3085 - accuracy: 0.6874\n\nEpoch 6: saving model to checkpoints/model_06.ckpt\n\n2425/2425 [==============================] - 1723s 710ms/step - loss: 1.3085 - accuracy: 0.6874 - val_loss: 1.0954 - val_accuracy: 0.7295\n\nEpoch 7/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.2053 - accuracy: 0.7057\n\nEpoch 7: saving model to checkpoints/model_07.ckpt\n\n2425/2425 [==============================] - 1773s 731ms/step - loss: 1.2053 - accuracy: 0.7057 - val_loss: 0.9872 - val_accuracy: 0.7523\n\nEpoch 8/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.1126 - accuracy: 0.7231\n\nEpoch 8: saving model to checkpoints/model_08.ckpt\n\n2425/2425 [==============================] - 1735s 716ms/step - loss: 1.1126 - accuracy: 0.7231 - val_loss: 0.8870 - val_accuracy: 0.7747\n\nEpoch 9/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.7386\n\nEpoch 9: saving model to checkpoints/model_09.ckpt\n\n2425/2425 [==============================] - 1773s 731ms/step - loss: 1.0341 - accuracy: 0.7386 - val_loss: 0.8075 - val_accuracy: 0.7940\n\nEpoch 10/10\n\n2425/2425 [==============================] - ETA: 0s - loss: 0.9785 - accuracy: 0.7498\n\nEpoch 10: saving model to checkpoints/model_10.ckpt\n\n2425/2425 [==============================] - 1785s 736ms/step - loss: 0.9785 - accuracy: 0.7498 - val_loss: 0.7581 - val_accuracy: 0.8066\n"}]},{"cell_type":"code","source":"import json\nimport os\n\n# Directorio para guardar los datos\ndata_dir = \"data\"\nos.makedirs(data_dir, exist_ok=True)\n\n# Ruta del archivo para guardar la variable history como JSON\nhistory_file = os.path.join(data_dir, \"history.json\")\n\n# Convertir el diccionario 'history.history' a formato JSON y guardarlo en un archivo\nwith open(history_file, 'w') as f:\n    json.dump(history.history, f)","metadata":{"execution":{"iopub.execute_input":"2023-08-06T05:14:56.504954Z","iopub.status.busy":"2023-08-06T05:14:56.503929Z","iopub.status.idle":"2023-08-06T05:14:56.512193Z","shell.execute_reply":"2023-08-06T05:14:56.511278Z"},"papermill":{"duration":2.186753,"end_time":"2023-08-06T05:14:56.514457","exception":false,"start_time":"2023-08-06T05:14:54.327704","status":"completed"},"tags":[]},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tensorflow.keras.callbacks import Callback\n\n# Obtener los tiempos por época y tiempo acumulado\ntimes_per_epoch = time_callback.times\ncumulative_time = [sum(times_per_epoch[:i+1]) for i in range(len(times_per_epoch))]\n\n# Ruta del directorio para guardar los tiempos en un archivo de texto\ntime_dir = \"time\"\nos.makedirs(time_dir, exist_ok=True)  # Crea la carpeta \"time\" si no existe\n\n# Ruta del archivo para guardar los tiempos en un archivo de texto\ntime_file = os.path.join(time_dir, \"tiempos.txt\")\n\n# Guardar la salida en el archivo de texto\nwith open(time_file, 'w') as f:\n    print(\"Tiempos por época:\", times_per_epoch, file=f)\n    print(\"Tiempo acumulado:\", cumulative_time, file=f)\n\n# También puedes imprimir los resultados en la consola si lo deseas\nprint(\"Tiempos por época:\", times_per_epoch)\nprint(\"Tiempo acumulado:\", cumulative_time)","metadata":{"execution":{"iopub.execute_input":"2023-08-06T05:15:00.651435Z","iopub.status.busy":"2023-08-06T05:15:00.651042Z","iopub.status.idle":"2023-08-06T05:15:00.661858Z","shell.execute_reply":"2023-08-06T05:15:00.660797Z"},"papermill":{"duration":2.128604,"end_time":"2023-08-06T05:15:00.664399","exception":false,"start_time":"2023-08-06T05:14:58.535795","status":"completed"},"tags":[]},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"Tiempos por época: [1851.9821662902832, 1708.822984457016, 1704.590767621994, 1755.7161228656769, 1713.3261742591858, 1724.6881439685822, 1775.269733428955, 1737.0464487075806, 1774.6841344833374, 1786.9337086677551]\n\nTiempo acumulado: [1851.9821662902832, 3560.805150747299, 5265.395918369293, 7021.11204123497, 8734.438215494156, 10459.126359462738, 12234.396092891693, 13971.442541599274, 15746.126676082611, 17533.060384750366]\n"}]},{"cell_type":"markdown","source":"\n##  Métricas y parámetros para evaluar el rendimiento y la eficiencia durante el entrenamiento.\n\nUna vez terminado el entrenamiento podemos visualizar y monitorear el rendimiento del modelo durante el entrenamiento, proporcionando métricas como pérdida, precisión, tasa de aprendizaje y eficiencia computacional.","metadata":{"id":"2qY8BXrtv8rG","papermill":{"duration":2.196201,"end_time":"2023-08-06T05:15:04.909547","exception":false,"start_time":"2023-08-06T05:15:02.713346","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Obtener las métricas de pérdida, precisión y tasa de aprendizaje durante el entrenamiento\nloss = history.history['loss']\naccuracy = history.history['accuracy'] # Reemplaza 'accuracy' con 'weighted_accuracy' si estás utilizando esta métrica\nlearning_rate = np.array([learning_rate[step] for step in range(len(history.epoch))])\n\n# Obtener la eficiencia computacional\ntime_per_epoch = history.epoch[-1] / len(history.epoch)  # Tiempo por época\nefficiency = [time_per_epoch * (i + 1) for i in range(num_epochs)]\n\n# Graficar la pérdida, precisión, tasa de aprendizaje y eficiencia\nepochs = range(1, num_epochs + 1)\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 4, 1)\nplt.plot(epochs, loss, 'b', label='Pérdida')\nplt.title('Pérdida durante el entrenamiento')\nplt.xlabel('Épocas')\nplt.ylabel('Valor')\nplt.legend()\n\nplt.subplot(1, 4, 2)\nplt.plot(epochs, accuracy, 'r', label='Precisión')\nplt.title('Precisión durante el entrenamiento')\nplt.xlabel('Épocas')\nplt.ylabel('Valor')\nplt.legend()\n\nplt.subplot(1, 4, 3)\nplt.plot(epochs, learning_rate, 'g', label='Tasa de Aprendizaje')\nplt.title('Tasa de Aprendizaje durante el entrenamiento')\nplt.xlabel('Épocas')\nplt.ylabel('Valor')\nplt.legend()\n\nplt.subplot(1, 4, 4)\nplt.plot(epochs, efficiency, 'm', label='Eficiencia')\nplt.title('Eficiencia Computacional durante el entrenamiento')\nplt.xlabel('Épocas')\nplt.ylabel('Tiempo (segundos)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"C50bH5ynv6He","outputId":"39818c80-cb7f-4259-b014-c39085809e48","papermill":{"duration":2.005495,"end_time":"2023-08-06T05:15:09.039973","exception":false,"start_time":"2023-08-06T05:15:07.034478","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Una vez finalizado el ajuste fino, puedes generar texto nuevamente utilizando la misma función generate(). Esta vez, el texto estará más cerca del estilo de wikihow y la longitud generada será similar a la longitud preestablecida en el conjunto de entrenamiento.","metadata":{"id":"vWNubPGvzb78","papermill":{"duration":2.017939,"end_time":"2023-08-06T05:15:13.191776","exception":false,"start_time":"2023-08-06T05:15:11.173837","status":"completed"},"tags":[]}},{"cell_type":"code","source":"start = time.time()\n\n\noutput = gpt2_lm.generate(\"¿Como jugar videojuegos?\", max_length=200)\nprint(\"\\nGPT-2 output:\")\nprint(output)\n\nend = time.time()\nprint(f\"TIEMPO TOTAL TRANSCURRIDO: {end - start:.2f}s\")","metadata":{"execution":{"iopub.execute_input":"2023-08-06T05:15:17.414387Z","iopub.status.busy":"2023-08-06T05:15:17.413960Z","iopub.status.idle":"2023-08-06T05:15:34.858209Z","shell.execute_reply":"2023-08-06T05:15:34.856740Z"},"id":"0GsZi7DUzb78","outputId":"2962860e-ebf8-4ae1-e65d-909251dc6184","papermill":{"duration":19.445519,"end_time":"2023-08-06T05:15:34.860685","exception":false,"start_time":"2023-08-06T05:15:15.415166","status":"completed"},"tags":[]},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\nGPT-2 output:\n\n¿Como jugar videojuegos?\n\nPreparar el juego:\n\nDetermina el objetivo del juego. Determina cuál será el orden que realizará el juego. Elige el número de jugadores para el juego.\n\nAntes de que jugar videojuegos, debes tener en cuenta que el juego es el juego que determinará si quieres jugar otra persona, así como un equipo. Sin embargo,\n\nTIEMPO TOTAL TRANSCURRIDO: 17.44s\n"}]},{"cell_type":"markdown","source":"## Acerca del Método de Muestreo\n\nEn KerasNLP, ofrecemos varios métodos de muestreo, como la búsqueda contrastiva, el muestreo Top-K y el muestreo de haz (beam sampling). Por defecto, nuestro `GPT2CausalLM` utiliza el muestreo Top-K, pero puedes elegir tu propio método de muestreo.\n\nAl igual que con el optimizador y las funciones de activación, hay dos formas de especificar tu propio muestreador personalizado:\n\n- Utilizar un identificador de cadena, como \"greedy\", si deseas utilizar la configuración predeterminada de esta forma.\n- Pasar una instancia de `keras_nlp.samplers.Sampler`, si deseas utilizar una configuración personalizada de esta forma.","metadata":{"id":"eL9KgIgXzb78","papermill":{"duration":2.11124,"end_time":"2023-08-06T05:15:39.086206","exception":false,"start_time":"2023-08-06T05:15:36.974966","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Use a string identifier.\ngpt2_lm.compile(sampler=\"top_k\")\noutput = gpt2_lm.generate(\"Como escribir un ensayo\", max_length=200)\nprint(\"\\nGPT-2 output:\")\nprint(output)\n\n# Use a `Sampler` instance. `GreedySampler` tends to repeat itself,\ngreedy_sampler = keras_nlp.samplers.GreedySampler()\ngpt2_lm.compile(sampler=greedy_sampler)\n\noutput = gpt2_lm.generate(\"Como escribir un ensayo\", max_length=200)\nprint(\"\\nGPT-2 output:\")\nprint(output)","metadata":{"execution":{"iopub.execute_input":"2023-08-06T05:15:43.225397Z","iopub.status.busy":"2023-08-06T05:15:43.224990Z","iopub.status.idle":"2023-08-06T05:16:18.975402Z","shell.execute_reply":"2023-08-06T05:16:18.972621Z"},"id":"bWRmzJBmzb78","outputId":"7573bd91-93dd-4ad2-8acb-e6268868f020","papermill":{"duration":39.856886,"end_time":"2023-08-06T05:16:20.952495","exception":false,"start_time":"2023-08-06T05:15:41.095609","status":"completed"},"tags":[]},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\nGPT-2 output:\n\nComo escribir un ensayo de comparación y contraste?\n\nEscribir tu propio ensayo de comparación y contraste:\n\nPiensa en un tema. Escribe la oración y el enunciado. Escribe el cuerpo de la oración y el enunciado. Escribe una introducción. Escribe una conclusión. Escribe una conclusión. Escribe una conclusión.\n\nSi tienes mucha experiencia, es probable que te hagan sentir un\n\n\n\nGPT-2 output:\n\nComo escribir un ensayo de comparación y contraste?\n\nEscribir el ensayo:\n\nEscribe una introducción. Escribe una conclusión. Escribe una conclusión informal. Escribe una conclusión más personal. Escribe una conclusión más cortés. Escribe una conclusión más abierta.\n\nEmpieza con una conclusión que tenga una conclusión general de tu tema o de tu situación\n"}]},{"cell_type":"markdown","source":"Para obtener más detalles sobre la clase `Sampler` de KerasNLP, puedes revisar el código [aquí](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/samplers).","metadata":{"id":"QGvtOoQRzb78","papermill":{"duration":2.063856,"end_time":"2023-08-06T05:16:25.118339","exception":false,"start_time":"2023-08-06T05:16:23.054483","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Guarda tu Modelo\n","metadata":{"id":"jPmGoVk64AuE","papermill":{"duration":2.150414,"end_time":"2023-08-06T05:16:29.858049","exception":false,"start_time":"2023-08-06T05:16:27.707635","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"*** Guarda el modelo: Utiliza el método model.save() de Keras para guardar todo el modelo, incluyendo la configuración y los pesos, en un archivo. Especifica una ruta y un nombre de archivo para guardar el modelo","metadata":{"id":"d2j2nDXCb5eA","papermill":{"duration":2.16942,"end_time":"2023-08-06T05:16:34.008344","exception":false,"start_time":"2023-08-06T05:16:31.838924","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import os\nsave_dir = \"saved_model_h5\"\nos.makedirs(save_dir, exist_ok=True)\nmodel.save(\"saved_model_h5/model.h5\")","metadata":{"id":"56ovHweLb4qk","papermill":{"duration":1.998676,"end_time":"2023-08-06T05:16:38.104585","exception":false,"start_time":"2023-08-06T05:16:36.105909","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":" Si estás trabajando principalmente con TensorFlow y planeas utilizar el modelo en otros proyectos o plataformas compatibles con SavedModel, entonces tf.saved_model.save() puede ser más conveniente.","metadata":{"id":"CcL8nILicdH9","papermill":{"duration":1.97922,"end_time":"2023-08-06T05:16:42.181796","exception":false,"start_time":"2023-08-06T05:16:40.202576","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import os\nsave_dir2 = \"saved_model_tf\"\nos.makedirs(save_dir2, exist_ok=True)\ntf.saved_model.save(gpt2_lm, saved_model_dir)","metadata":{"id":"SUskIFtacmZQ","papermill":{"duration":1.959597,"end_time":"2023-08-06T05:16:46.322615","exception":false,"start_time":"2023-08-06T05:16:44.363018","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Restaura tu modelo desde un checkpoint\n","metadata":{"id":"jPmGoVk64AuE","papermill":{"duration":1.992672,"end_time":"2023-08-06T05:16:50.405092","exception":false,"start_time":"2023-08-06T05:16:48.412420","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n    \"gpt2_base_en\",\n    sequence_length=128,\n)\ngpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n    \"gpt2_base_en\", preprocessor=preprocessor\n)","metadata":{"papermill":{"duration":2.173523,"end_time":"2023-08-06T05:16:54.667577","exception":false,"start_time":"2023-08-06T05:16:52.494054","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Crear el modelo con la misma arquitectura\npreprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n    \"gpt2_base_en\",\n    sequence_length=128,\n)\ngpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n    \"gpt2_base_en\", preprocessor=preprocessor\n)\n\n# Directorio donde se encuentran los pesos guardados\ncheckpoint_dir = \"checkpoints/\"\n\n# Verificar si hay checkpoints existentes para cargar los pesos desde el último\ncheckpoint_files = [file for file in os.listdir(checkpoint_dir) if file.endswith('.ckpt.index')]\nif checkpoint_files:\n    latest_checkpoint = max(checkpoint_files)\n    print(\"Ultimo checkpoint: \", latest_checkpoint)\n    gpt2_lm.load_weights(os.path.join(checkpoint_dir, latest_checkpoint[:-6]))\n","metadata":{"papermill":{"duration":2.586256,"end_time":"2023-08-06T05:16:59.249462","exception":false,"start_time":"2023-08-06T05:16:56.663206","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"loss,acc = gpt2_lm.evaluate(train_ds, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))","metadata":{"papermill":{"duration":2.129924,"end_time":"2023-08-06T05:17:03.406315","exception":false,"start_time":"2023-08-06T05:17:01.276391","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"start = time.time()\n\noutput = gpt2_lm.generate(\"Como conseguir diamante en minecraft\", max_length=200)\nprint(\"\\nGPT-2 output:\")\nprint(output)\n\nend = time.time()\nprint(f\"TIEMPO TOTAL TRANSCURRIDO: {end - start:.2f}s\")","metadata":{"papermill":{"duration":2.153051,"end_time":"2023-08-06T05:17:07.619857","exception":false,"start_time":"2023-08-06T05:17:05.466806","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import os\n\ninput_dir = '/kaggle/input'\nfiles = [file for file in os.listdir(input_dir)]\nprint(files)\n\nfor file in files:\n    file_path = os.path.join(input_dir, file)\n    file_size_bytes = os.stat(file_path).st_size\n    file_size_mb = file_size_bytes / 1048576  # 1 MB = 1048576 bytes\n    print(f\"File: {file}, Size: {file_size_mb:.2f} MB\")\n","metadata":{"papermill":{"duration":2.007863,"end_time":"2023-08-06T05:17:11.736667","exception":false,"start_time":"2023-08-06T05:17:09.728804","status":"completed"},"tags":[]}}]}